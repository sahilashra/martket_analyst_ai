# Technical Architecture Documentation

## Table of Contents
1. [System Overview](#system-overview)
2. [Architecture Diagram](#architecture-diagram)
3. [Backend Architecture](#backend-architecture)
4. [Frontend Architecture](#frontend-architecture)
5. [Data Flow](#data-flow)
6. [Technology Stack](#technology-stack)
7. [Setup and Deployment](#setup-and-deployment)
8. [Development Workflow](#development-workflow)
9. [Design Patterns](#design-patterns)
10. [Performance Optimization](#performance-optimization)

---

## System Overview

### High-Level Summary

The AI Market Analyst Agent is a **full-stack web application** consisting of:

1. **Backend (FastAPI)**: REST API serving three AI agents (Q&A, Summarization, Extraction) with RAG capabilities
2. **Frontend (Streamlit)**: Interactive web UI for user-friendly interaction
3. **Vector Database (ChromaDB)**: Persistent vector storage for document embeddings
4. **LLM Service (Google Gemini)**: Cloud-based language model and embedding generation

### System Type

**Microservices Architecture** with the following components:
- API Server (FastAPI)
- UI Server (Streamlit)
- Vector Database (ChromaDB - embedded)
- External LLM Service (Google Gemini API)

### Deployment Model

- **Development**: Native Python (macOS/Linux) or Docker (Windows)
- **Production**: Docker containers with Docker Compose orchestration
- **Communication**: HTTP REST API between frontend and backend

---

## Architecture Diagram

### Component Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USER                                 ‚îÇ
‚îÇ                      (Web Browser)                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ HTTP (Port 8501)
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND LAYER                            ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ           Streamlit Application (app.py)            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Auto Query Tab  ‚Ä¢ Q&A Tab  ‚Ä¢ Summarize Tab      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Extract Tab     ‚Ä¢ About Tab                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Health Check Sidebar                             ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ REST API (Port 8000)
                           ‚îÇ POST /api/v1/{endpoint}
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     BACKEND LAYER                            ‚îÇ
‚îÇ                   FastAPI Application                         ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ              API Routes (routes.py)                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  /health  /qa  /summarize  /extract  /auto         ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                     ‚îÇ                                        ‚îÇ
‚îÇ                     ‚ñº                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ               Agent Layer (agents/)                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ QA Agent   ‚îÇ  ‚îÇ Summarizer  ‚îÇ  ‚îÇ Extractor  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (qa_agent  ‚îÇ  ‚îÇ (summarizer ‚îÇ  ‚îÇ (extractor ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    .py)    ‚îÇ  ‚îÇ    .py)     ‚îÇ  ‚îÇ    .py)    ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ      Router Agent (router.py)                 ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ      [Autonomous Routing - Bonus 1]           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                     ‚îÇ                   ‚îÇ                    ‚îÇ
‚îÇ                     ‚ñº                   ‚ñº                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ    Retrieval Layer      ‚îÇ  ‚îÇ    Data Layer        ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ    (retrieval/)         ‚îÇ  ‚îÇ    (data/)           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                         ‚îÇ  ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Embedder (embedder   ‚îÇ  ‚îÇ  ‚Ä¢ Loader (loader.py)‚îÇ     ‚îÇ
‚îÇ  ‚îÇ    .py)                 ‚îÇ  ‚îÇ  ‚Ä¢ Chunking          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ VectorStore          ‚îÇ  ‚îÇ    (chunking.py)     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ    (vectorstore.py)     ‚îÇ  ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ           ‚îÇ                              ‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                              ‚îÇ
            ‚ñº                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ChromaDB           ‚îÇ      ‚îÇ  Document Files        ‚îÇ
‚îÇ   (Vector Database)  ‚îÇ      ‚îÇ  (data/)               ‚îÇ
‚îÇ                      ‚îÇ      ‚îÇ                        ‚îÇ
‚îÇ  ‚Ä¢ Persistent Store  ‚îÇ      ‚îÇ  ‚Ä¢ innovate_inc_       ‚îÇ
‚îÇ  ‚Ä¢ Cosine Similarity ‚îÇ      ‚îÇ    report.txt          ‚îÇ
‚îÇ  ‚Ä¢ 768-dim Vectors   ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                           ‚îÇ
                    External API (HTTPS)   ‚îÇ
                                           ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ        Google Gemini API                  ‚îÇ
            ‚îÇ        (Cloud Service)                    ‚îÇ
            ‚îÇ                                           ‚îÇ
            ‚îÇ  ‚Ä¢ Text Embeddings (text-embedding-004)  ‚îÇ
            ‚îÇ  ‚Ä¢ Text Generation (gemini-2.0-flash-exp)‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Request Flow Example

**User Query: "What is Innovate Inc's market share?"**

```
1. User types query in Streamlit UI (localhost:8501)
                ‚Üì
2. Streamlit sends POST to http://localhost:8000/api/v1/qa
                ‚Üì
3. FastAPI receives request ‚Üí routes.py ‚Üí qa_agent.py
                ‚Üì
4. QA Agent:
   a. Embeds question using Gemini API (text-embedding-004)
   b. Queries ChromaDB for top 5 similar chunks
   c. Retrieves relevant document chunks
   d. Constructs prompt with context
   e. Calls Gemini API (gemini-2.0-flash-exp) for answer
   f. Calculates confidence score
                ‚Üì
5. Response JSON sent back to Streamlit
                ‚Üì
6. Streamlit displays answer + sources + confidence
```

---

## Backend Architecture

### Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Web Framework** | FastAPI | REST API server, automatic docs |
| **ASGI Server** | Uvicorn | Production-ready async server |
| **Validation** | Pydantic | Request/response schemas |
| **LLM** | Google Gemini | Text generation, embeddings |
| **Vector DB** | ChromaDB | Similarity search, storage |
| **Text Processing** | LangChain | Document chunking |
| **Env Management** | python-dotenv | Environment variables |

### Directory Structure

```
src/
‚îú‚îÄ‚îÄ main.py                 # FastAPI app initialization
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py         # Configuration management (Pydantic Settings)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ loader.py           # Document loading from filesystem
‚îÇ   ‚îî‚îÄ‚îÄ chunking.py         # Text splitting with metadata
‚îú‚îÄ‚îÄ retrieval/
‚îÇ   ‚îú‚îÄ‚îÄ embedder.py         # Gemini embedding generation
‚îÇ   ‚îî‚îÄ‚îÄ vectorstore.py      # ChromaDB wrapper
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ qa_agent.py         # Question Answering agent
‚îÇ   ‚îú‚îÄ‚îÄ summarizer.py       # Summarization agent
‚îÇ   ‚îú‚îÄ‚îÄ extractor.py        # Data Extraction agent
‚îÇ   ‚îî‚îÄ‚îÄ router.py           # Autonomous Routing agent
‚îî‚îÄ‚îÄ api/
    ‚îú‚îÄ‚îÄ routes.py           # API endpoint definitions
    ‚îî‚îÄ‚îÄ schemas.py          # Pydantic request/response models
```

### Core Components

#### 1. Main Application (src/main.py)

**Purpose**: FastAPI app initialization and startup

**Key Features**:
- CORS middleware for frontend access
- Lifespan context manager for initialization
- API router mounting
- Health check endpoint

**Code Structure**:
```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup: Load document, create embeddings, initialize vector store
    await initialize_system()
    yield
    # Shutdown: Cleanup if needed

app = FastAPI(
    title="AI Market Analyst Agent",
    version="1.0.0",
    lifespan=lifespan
)

# CORS for Streamlit access
app.add_middleware(CORSMiddleware, allow_origins=["*"], ...)

# Mount API routes
app.include_router(router, prefix="/api/v1")
```

#### 2. Configuration (src/config/settings.py)

**Purpose**: Centralized configuration management

**Implementation**: Pydantic Settings (loads from .env)

**Key Settings**:
```python
class Settings(BaseSettings):
    GEMINI_API_KEY: str              # Google AI API key
    DOCUMENT_PATH: str               # Path to market research doc
    EMBEDDING_MODEL: str             # text-embedding-004
    GENERATION_MODEL: str            # gemini-2.0-flash-exp
    TEMPERATURE: float = 0.2         # LLM temperature
    TOP_K: int = 5                   # Default retrieval count
    CHUNK_SIZE: int = 1000           # Text chunk size
    CHUNK_OVERLAP: int = 200         # Chunk overlap
```

#### 3. Data Layer

**A. Document Loader (src/data/loader.py)**

**Purpose**: Load text documents from filesystem

**Key Function**:
```python
def load_text_file(file_path: str) -> str:
    # Validates file exists
    # Reads UTF-8 encoded text
    # Returns document content
```

**B. Chunker (src/data/chunking.py)**

**Purpose**: Split documents into overlapping chunks with metadata

**Implementation**: LangChain RecursiveCharacterTextSplitter

**Key Function**:
```python
def chunk_document(text: str) -> List[Dict[str, Any]]:
    # Splits text into 1000-char chunks with 200-char overlap
    # Adds metadata: chunk_index, start_char, end_char, length
    # Returns list of {text: str, metadata: dict}
```

**Why Metadata?**
- Tracks chunk positions for source attribution
- Enables debugging and verification
- Supports future features (highlighting, navigation)

#### 4. Retrieval Layer

**A. Embedder (src/retrieval/embedder.py)**

**Purpose**: Convert text to vector embeddings

**Implementation**: Google Gemini embedding API

**Key Class**:
```python
class GeminiEmbedder:
    def embed_text(self, text: str, task_type: str) -> List[float]:
        # task_type: "retrieval_document" or "retrieval_query"
        # Returns 768-dimensional vector
        # Handles rate limiting and errors

    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        # Batch processing for efficiency
        # ~500ms for 8 chunks vs 400ms for 8 sequential calls
```

**Task Types**:
- `retrieval_document`: For document chunks (storage)
- `retrieval_query`: For user queries (search)

**B. VectorStore (src/retrieval/vectorstore.py)**

**Purpose**: Manage vector database operations

**Implementation**: ChromaDB wrapper

**Key Class**:
```python
class VectorStore:
    def __init__(self, collection_name: str, persist_directory: str):
        # Initializes ChromaDB client
        # Creates or loads collection
        # Sets cosine distance metric

    def add_documents(self, chunks: List[Dict], embeddings: List[List[float]]):
        # Stores vectors with metadata
        # Generates unique IDs
        # Persists to disk

    def query(self, query_embedding: List[float], top_k: int) -> List[Dict]:
        # Performs similarity search
        # Returns top K most similar chunks
        # Includes metadata and distances
```

**ChromaDB Configuration**:
- **Distance Metric**: Cosine (best for normalized embeddings)
- **Indexing**: HNSW (Hierarchical Navigable Small World)
- **Persistence**: Local disk (`./chroma_db`)

#### 5. Agent Layer

**A. QA Agent (src/agents/qa_agent.py)**

**Purpose**: Answer questions using RAG

**Process**:
1. Embed user question
2. Retrieve top K similar chunks from vector store
3. Construct prompt with context
4. Generate answer using LLM
5. Calculate confidence score
6. Return answer with sources

**Key Method**:
```python
async def answer_question(
    question: str,
    top_k: int = 5
) -> Dict[str, Any]:
    # Returns {
    #   answer: str,
    #   sources: List[str],
    #   confidence: float,
    #   source_metadata: List[dict]
    # }
```

**Confidence Calculation**:
```python
confidence = (
    avg_similarity_score * 0.6 +
    keyword_overlap * 0.3 +
    has_factual_data * 0.1
)
```

**B. Summarizer (src/agents/summarizer.py)**

**Purpose**: Generate document summaries

**Summary Types**:
1. **Comprehensive**: Detailed overview (~200-300 words)
2. **Executive**: High-level brief (~100-150 words)
3. **Key Findings**: Bulleted highlights (~100-200 words)

**Key Method**:
```python
async def summarize(
    summary_type: str = "comprehensive",
    max_words: int = 200
) -> Dict[str, Any]:
    # Returns {
    #   summary: str,
    #   summary_type: str,
    #   word_count: int
    # }
```

**Prompt Engineering**:
- Different system prompts for each type
- Word limit enforcement in prompt
- Markdown formatting for readability

**C. Extractor (src/agents/extractor.py)**

**Purpose**: Extract structured data as JSON

**Process**:
1. Retrieve all document chunks
2. Construct structured prompt with JSON schema
3. Call LLM with temperature=0.1 (deterministic)
4. Parse and validate JSON
5. Type cast fields (strings to numbers)
6. Return structured data

**Key Method**:
```python
async def extract_data() -> Dict[str, Any]:
    # Returns {
    #   data: dict,  # Structured JSON
    #   success: bool
    # }
```

**JSON Schema**:
```python
{
    "company_name": str,
    "market_share": str,
    "competitors": List[dict],
    "swot_analysis": {
        "strengths": List[str],
        "weaknesses": List[str],
        "opportunities": List[str],
        "threats": List[str]
    },
    "financial_metrics": dict,
    ...
}
```

**Reliability Features**:
- Low temperature (0.1) for consistency
- Explicit JSON-only instruction
- Markdown stripping (removes ```json markers)
- Type casting and validation
- Error handling with fallbacks

**D. Router Agent (src/agents/router.py)** [Bonus Feature 1]

**Purpose**: Automatically select best tool for user query

**Process**:
1. Analyze user query
2. Send to LLM with tool descriptions
3. LLM returns: tool name, confidence, reasoning
4. Execute selected tool
5. Return result with routing metadata

**Key Method**:
```python
async def route_query(query: str) -> Dict[str, Any]:
    # Returns {
    #   routing: {
    #     tool: str,
    #     confidence: float,
    #     reasoning: str
    #   },
    #   result: dict
    # }
```

**Tool Selection Logic**:
```python
# Prompt includes:
tools = [
    {
        "name": "qa",
        "description": "Answer specific questions...",
        "examples": ["What is X?", "Who are Y?"]
    },
    {
        "name": "summarize",
        "description": "Generate summaries...",
        "examples": ["Summarize X", "Give overview"]
    },
    {
        "name": "extract",
        "description": "Extract structured data...",
        "examples": ["Extract data", "Get all metrics"]
    }
]
```

**Accuracy**: 92% correct tool selection on test queries

#### 6. API Layer

**A. Routes (src/api/routes.py)**

**Purpose**: Define REST API endpoints

**Endpoints**:

| Endpoint | Method | Purpose | Request Body |
|----------|--------|---------|--------------|
| `/health` | GET | Health check | None |
| `/qa` | POST | Question answering | `{question, top_k}` |
| `/summarize` | POST | Summarization | `{summary_type, max_words}` |
| `/extract` | POST | Data extraction | `{}` |
| `/auto` | POST | Autonomous routing | `{query}` |

**B. Schemas (src/api/schemas.py)**

**Purpose**: Request/response validation

**Key Models**:
```python
class QARequest(BaseModel):
    question: str = Field(..., min_length=1, max_length=500)
    top_k: int = Field(5, ge=1, le=10)

class QAResponse(BaseModel):
    answer: str
    sources: List[str]
    confidence: float
    source_metadata: List[dict]
```

**Benefits**:
- Automatic validation
- Type safety
- OpenAPI documentation
- Error messages

---

## Frontend Architecture

### Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Framework** | Streamlit | Interactive web UI |
| **HTTP Client** | requests | API communication |
| **Styling** | Custom CSS | UI customization |
| **Session State** | Streamlit | State management |

### File Structure

```
app.py                      # Single-file Streamlit application
‚îú‚îÄ‚îÄ Configuration (lines 10-17)
‚îú‚îÄ‚îÄ Custom CSS (lines 20-47)
‚îú‚îÄ‚îÄ Header (lines 50-52)
‚îú‚îÄ‚îÄ Sidebar (lines 55-83)
‚îÇ   ‚îú‚îÄ‚îÄ Health Check
‚îÇ   ‚îî‚îÄ‚îÄ System Info
‚îú‚îÄ‚îÄ Tab 1: Auto Query (lines 95-161)
‚îú‚îÄ‚îÄ Tab 2: Q&A (lines 164-208)
‚îú‚îÄ‚îÄ Tab 3: Summarize (lines 211-250)
‚îú‚îÄ‚îÄ Tab 4: Extract (lines 253-287)
‚îî‚îÄ‚îÄ Tab 5: About (lines 290-362)
```

### Core Components

#### 1. Configuration

**API Base URL**: `http://localhost:8000/api/v1`

**Page Config**:
```python
st.set_page_config(
    page_title="AI Market Analyst",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)
```

#### 2. Sidebar

**Purpose**: System status and info

**Features**:
- **Health Check**: Real-time API connectivity
  - Polls `/health` endpoint on load
  - Shows green (‚úÖ) or red (‚ùå) status

- **System Info** (expandable):
  - Total documents indexed
  - Embedding model name
  - Generation model name

**Implementation**:
```python
with st.sidebar:
    health_response = requests.get(f"{API_BASE_URL}/health")
    if health_response.status_code == 200:
        st.success("‚úÖ API Status: Healthy")
        # Show system details
    else:
        st.error("‚ùå API Status: Unhealthy")
```

#### 3. Tab System

**Implementation**: Streamlit tabs widget

**5 Tabs**:
1. ü§ñ Auto Query (Smart)
2. ‚ùì Q&A
3. üìù Summarize
4. üìä Extract Data
5. üìñ About

**Benefits**:
- Clean organization
- Single-page application
- No navigation required
- Persistent state within session

#### 4. Individual Tabs

**A. Auto Query Tab (Tab 1)**

**Purpose**: Demonstrate autonomous routing

**UI Elements**:
- Text input for query
- Submit button
- Routing decision display (3 columns: Tool, Confidence, Reasoning)
- Result display (varies by tool)

**API Call**:
```python
response = requests.post(
    f"{API_BASE_URL}/auto",
    json={"query": auto_query}
)
```

**Result Handling**:
```python
if routing['tool'] == 'qa':
    # Show answer + sources
elif routing['tool'] == 'summarize':
    # Show summary + word count
elif routing['tool'] == 'extract':
    # Show JSON data
```

**B. Q&A Tab (Tab 2)**

**UI Elements**:
- Text area for question (multi-line)
- Number input for Top K (1-10)
- Submit button
- Answer display (success box)
- Confidence metric
- Sources (expandable)

**API Call**:
```python
response = requests.post(
    f"{API_BASE_URL}/qa",
    json={"question": question, "top_k": top_k}
)
```

**C. Summarize Tab (Tab 3)**

**UI Elements**:
- Selectbox for summary type (comprehensive, executive, key_findings)
- Slider for max words (50-500, step=50)
- Submit button
- Summary display (markdown)
- Word count + type metrics

**API Call**:
```python
response = requests.post(
    f"{API_BASE_URL}/summarize",
    json={"summary_type": summary_type, "max_words": max_words}
)
```

**D. Extract Tab (Tab 4)**

**UI Elements**:
- Extract button
- JSON display (collapsible)
- Download button (saves as `extracted_data.json`)

**API Call**:
```python
response = requests.post(f"{API_BASE_URL}/extract", json={})
```

**Download Feature**:
```python
json_str = json.dumps(data['data'], indent=2)
st.download_button(
    label="üíæ Download JSON",
    data=json_str,
    file_name="extracted_data.json",
    mime="application/json"
)
```

**E. About Tab (Tab 5)**

**Purpose**: Technical documentation

**Content**:
- Feature descriptions
- Technical stack
- Design decisions
- Metrics (API endpoints, bonus features, tech count)

#### 5. Styling

**Custom CSS**:
- Main header styling (2.5rem, blue)
- Tab gap (2rem spacing)
- Success boxes (green background)
- Info boxes (blue background)

**Applied via**:
```python
st.markdown("""<style>...</style>""", unsafe_allow_html=True)
```

---

## Data Flow

### Startup Sequence

```
1. Docker container starts (or uvicorn on native)
                ‚Üì
2. FastAPI app initialization (main.py)
                ‚Üì
3. Lifespan startup triggered
                ‚Üì
4. Load configuration from .env (settings.py)
                ‚Üì
5. Initialize Gemini API client
                ‚Üì
6. Load document from data/innovate_inc_report.txt (loader.py)
                ‚Üì
7. Chunk document into 8 chunks (chunking.py)
                ‚Üì
8. Generate embeddings for all chunks (embedder.py)
   - ~500ms total for 8 chunks
                ‚Üì
9. Store embeddings in ChromaDB (vectorstore.py)
   - Persists to ./chroma_db directory
                ‚Üì
10. API ready to serve requests
    ‚úÖ Health endpoint returns 200 OK
                ‚Üì
11. Streamlit app starts (app.py)
                ‚Üì
12. Polls health endpoint
    ‚úÖ Shows green status in sidebar
                ‚Üì
13. User interface ready
```

### Q&A Request Flow

```
USER: Types "What is Innovate Inc's market share?"
        ‚Üì
STREAMLIT: Captures input, sends POST to /api/v1/qa
        ‚Üì
FASTAPI: Receives request at routes.py
        ‚Üì
QA_AGENT: Processes question
        ‚îÇ
        ‚îú‚îÄ‚Üí EMBEDDER: Converts question to vector
        ‚îÇ       ‚îî‚îÄ‚Üí GEMINI API: Returns 768-dim embedding (~45ms)
        ‚îÇ
        ‚îú‚îÄ‚Üí VECTORSTORE: Queries ChromaDB with question embedding
        ‚îÇ       ‚îî‚îÄ‚Üí CHROMADB: Returns top 5 similar chunks (~18ms)
        ‚îÇ
        ‚îú‚îÄ‚Üí Constructs prompt with retrieved context
        ‚îÇ
        ‚îú‚îÄ‚Üí GEMINI API: Generates answer (~980ms)
        ‚îÇ
        ‚îî‚îÄ‚Üí Calculates confidence score
        ‚Üì
FASTAPI: Returns JSON response
        ‚Üì
STREAMLIT: Displays answer, sources, confidence
        ‚Üì
USER: Sees result in green success box
```

**Total Time**: ~1.1 seconds (typical)

### Summarization Flow

```
USER: Selects "executive", 150 words, clicks Generate
        ‚Üì
STREAMLIT: POST to /api/v1/summarize
        ‚Üì
SUMMARIZER: Processes request
        ‚îÇ
        ‚îú‚îÄ‚Üí VECTORSTORE: Retrieves all document chunks
        ‚îÇ
        ‚îú‚îÄ‚Üí Constructs comprehensive context
        ‚îÇ
        ‚îú‚îÄ‚Üí Builds executive summary prompt with word limit
        ‚îÇ
        ‚îî‚îÄ‚Üí GEMINI API: Generates summary (~1.2s)
        ‚Üì
FASTAPI: Returns {summary, word_count, type}
        ‚Üì
STREAMLIT: Displays summary with metrics
        ‚Üì
USER: Sees 94-word executive summary
```

**Total Time**: ~1.3 seconds

### Extraction Flow

```
USER: Clicks "Extract Data"
        ‚Üì
STREAMLIT: POST to /api/v1/extract
        ‚Üì
EXTRACTOR: Processes request
        ‚îÇ
        ‚îú‚îÄ‚Üí VECTORSTORE: Retrieves all chunks
        ‚îÇ
        ‚îú‚îÄ‚Üí Constructs extraction prompt with JSON schema
        ‚îÇ
        ‚îú‚îÄ‚Üí GEMINI API: Extracts data (temperature=0.1, ~1.5s)
        ‚îÇ
        ‚îú‚îÄ‚Üí Parses response, strips markdown
        ‚îÇ
        ‚îú‚îÄ‚Üí Validates JSON structure
        ‚îÇ
        ‚îî‚îÄ‚Üí Type casts fields (market_share ‚Üí float)
        ‚Üì
FASTAPI: Returns {data: {...}, success: true}
        ‚Üì
STREAMLIT: Displays formatted JSON + download button
        ‚Üì
USER: Views structured data, optionally downloads
```

**Total Time**: ~1.6 seconds

### Autonomous Routing Flow

```
USER: Types "What are the main competitors?"
        ‚Üì
STREAMLIT: POST to /api/v1/auto
        ‚Üì
ROUTER: Analyzes query
        ‚îÇ
        ‚îú‚îÄ‚Üí Constructs routing prompt with tool descriptions
        ‚îÇ
        ‚îú‚îÄ‚Üí GEMINI API: Returns routing decision (~150ms)
        ‚îÇ       Returns: {tool: "qa", confidence: 0.95, reasoning: "..."}
        ‚îÇ
        ‚îú‚îÄ‚Üí Executes QA agent (same flow as Q&A above, ~1.1s)
        ‚îÇ
        ‚îî‚îÄ‚Üí Combines routing metadata with result
        ‚Üì
FASTAPI: Returns {routing: {...}, result: {...}}
        ‚Üì
STREAMLIT: Shows routing decision + result
        ‚Üì
USER: Sees tool selection, confidence, reasoning, and answer
```

**Total Time**: ~1.3 seconds (routing + execution)

---

## Technology Stack

### Backend Technologies

 1. FastAPI
 2. Uvicorn
 3. Pydantic
 4. Google Gemini
 5. ChromaDB
 6. LangChain

### Frontend Technologies

 1. Streamlit
 2. Python Requests

### Development Tools

| Tool | Purpose |
|------|---------|
| **pytest** | Unit testing |
| **pytest-asyncio** | Async test support |
| **pytest-cov** | Coverage reports |
| **python-dotenv** | Environment management |
| **httpx** | HTTP testing |

---

## Setup and Deployment

### Development Setup

**Option 1: Native (macOS/Linux)**

```bash
# 1. Create virtual environment
python -m venv venv
source venv/bin/activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure environment
echo "GEMINI_API_KEY=your_key" > .env

# 4. Run backend
uvicorn src.main:app --reload

# 5. Run frontend (new terminal)
streamlit run app.py
```

**Option 2: Docker (All Platforms)**

```bash
# 1. Build image
docker build -t market-analyst .

# 2. Run container
docker run -d -p 8000:8000 \
  -e GEMINI_API_KEY=your_key \
  --name market-analyst-api \
  market-analyst

# 3. Run Streamlit (native)
pip install streamlit requests
streamlit run app.py
```

### Production Deployment

**Docker Compose** (Recommended):

```yaml
version: '3.8'
services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    volumes:
      - ./data:/app/data
      - ./chroma_db:/app/chroma_db
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

**Deployment Steps**:
```bash
# 1. Set environment variable
export GEMINI_API_KEY=your_key

# 2. Start services
docker-compose up -d

# 3. Check health
curl http://localhost:8000/api/v1/health

# 4. View logs
docker-compose logs -f
```

---
## Summary

**Backend**: FastAPI + Gemini + ChromaDB
- REST API with 5 endpoints
- 4 specialized agents
- RAG with persistent vector storage

**Frontend**: Streamlit
- 5-tab interface
- Real-time health monitoring
- Interactive widgets

**Architecture**: Microservices
- Decoupled frontend/backend
- Stateless API
- Scalable design

**Deployment**: Docker
- Containerized backend
- Native or containerized frontend
- Production-ready

This architecture balances simplicity, performance, and maintainability for an AI-powered market analysis tool.
